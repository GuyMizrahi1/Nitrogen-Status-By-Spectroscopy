Best Configurations for xgboost_multi_output raised from Hyperparameter tuning:
{'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_lambda': 2}

Best Configurations for xgboost_multi_output_plsr raised from Hyperparameter tuning:
{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 0.1, 'reg_lambda': 2}